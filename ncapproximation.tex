\documentclass[]{article}

% Package `hyperref` must come before package `complexity`.
\usepackage[pdftitle={Definitions and reductions for NC approximation problems}, pdfauthor={Jeffrey Finkelstein}]{hyperref}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{complexity}
\usepackage{tikz}

\theoremstyle{plain}
\newtheorem{conjecture}{Conjecture}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}
\newtheorem{todo}{TODO}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{openquestion}{Open question}

\newenvironment{justification}{\begin{proof}[Justification]}{\end{proof}}

\newcommand{\definitionautorefname}{Definition}

\newcommand{\Er}{\leq_E^{L}}
\newcommand{\APr}{\leq_{AP}^{L}}
\newcommand{\email}[1]{\href{mailto:#1}{\nolinkurl{#1}}}
\newcommand{\lb}{\left\{}
\newcommand{\pb}{\textsf{pb}}
\newcommand{\rb}{\right\}}
\newcommand{\st}{\,\middle|\,}

\newcommand{\apxncoproblems}{%
  \textsc{Induced Subgraph of High Weight for Linear Extremal Properties} \cite{dsst97},
  \textsc{Maximum Acyclic Subgraph} \cite[Section~7.4]{dsst97},
  \textsc{Minimum $k$-Center} \cite[Section~7.4]{dsst97},
  \textsc{$k$-Switching Network} \cite[Section~7.4]{dsst97},
  \textsc{Maximum Bounded Weighted Satisfiability} \cite[Theorem~4]{sx95}}
\newcommand{\expapxncoproblems}{}
\newcommand{\frncasproblems}{%
  \textsc{Maximum Flow} \cite[Theorem~4.5.2]{dsst97},
  \textsc{Maximum Weight Perfect Matching} \cite[Theorem~4.5.2]{dsst97},
  \textsc{Maximum Weight Matching} \cite[Theorem~4.5.2]{dsst97}}
\newcommand{\fncasproblems}{%
  \textsc{Subset Sum} \cite[Theorem~4.1.4]{dsst97},
  \textsc{Maximum Satisfiability} \cite[Theorem~8]{trevisan98},
  \textsc{Minimum Weight Vertex Cover} \cite[Theorem~5.3.6]{dsst97},
  \textsc{0-1 Knapsack} \cite[Theorem~2]{mayr88},
  \textsc{Bin Packing} \cite[Theorem~3]{mayr88}}
\newcommand{\logapxncoproblems}{}
\newcommand{\ncasproblems}{%
  \textsc{Positive Linear Programming} \cite[Theorem~5.1.11]{dsst97},
  \textsc{Maximum $k$-Constraint Satisfaction Problem} \cite[Corollary~13]{trevisan98},
  \textsc{Maximum Matching} \cite[Theorem~5.2.1]{dsst97},
  \textsc{Maximum Flow} \cite[Theorem~5.2.2]{dsst97},
  \textsc{Maximum Weight Matching} \cite[Theorem~5.2.2]{dsst97},
  \textsc{Maximum Independent Set for Planar Graphs} \cite[Theorem 6.4.1]{dsst97}}
\newcommand{\ncoproblems}{}
\newcommand{\nncoproblems}{}
\newcommand{\polyapxncoproblems}{}
\newcommand{\rncasproblems}{%
  \textsc{Minimum Metric Traveling Salesperson} \cite[Theorem~7.1.1]{dsst97}}

\author{Jef{}frey Finkelstein}
\date{\today}
\title{Definitions and reductions for \texorpdfstring{\NC}{NC} approximation problems}

\begin{document}

\maketitle

\section{Introduction}

\NC{} is the class of computational problems decidable by a Boolean circuit of polynomial size and polylogarithmic depth.
Such problems are considered both ``efficient'' (since $\NC\subseteq\P$) and ``highly parallel'' (since we might consider each gate in the circuit to be a processor working in parallel and the low depth of the circuit a small number of steps).
By contrast, problems which are \P-complete (under \NC{} reductions) are considered ``inherently sequential''.
Furthermore, all \NP-hard and \PSPACE-hard problems are also inherently sequential, since $\P\subseteq\NP\subseteq\PSPACE$.
Just as we hope to find efficient approximation algorithms for optimization problems for which it is intractable to compute an exact solution, so too do we hope to find efficient and highly parallel approximation algorithms for optimization problems for which computing the exact solution is inherently sequential.
(However, just like hardness of approximation for \NP-hard problems, in some cases even \emph{approximating} a solution within a constant factor is inherently sequential!)

\section{Definitions for \texorpdfstring{\NC}{NC} approximation classes}

Throughout this work, $\Sigma=\{0, 1\}$ and inputs and outputs are encoded in binary.
The set of all finite strings is denoted $\Sigma^*$, and for each $x\in\Sigma^*$, we denote the length of $x$ by $|x|$.
We denote the set of all polynomials by \poly{} and the set of all polylogarithmic functions by \polylog.

\subsection{Optimization problems, approximators, and approximation schemes}

We adapt the clear and concise definitions of \cite{tantau07} from logarithmic space approximability to \NC{} approximability.

\begin{definition}[\cite{acgkmp99}]
  An \emph{optimization problem} is a four-tuple, $(I, S, m, t)$, where $I\subseteq \Sigma^*$ and is called the \emph{instance set}, $S\subseteq I\times \Sigma^*$ and is called the \emph{solution relation}, $m\colon S\to \mathbb{N}^+$ and is called the \emph{measure function}, and $t\in\{\min, \max\}$ and is called the type (of the optimization).
\end{definition}

\begin{definition}[\cite{tantau07}]
  Let $P$ be an optimization problem, so $P=(I, S, m, t)$, and let $x\in I$.
  \begin{enumerate}
  \item Let $S(x)=\lb y\in\Sigma^* \st (x, y)\in S \rb$; call this the \emph{solutions for $x$}.
  \item Define $m^*(x)$ by
    \begin{displaymath}
      m^*(x) =
      \begin{cases}
        \min \lb m(x, y) \st y\in S(x) \rb & \text{if } t = \min \\
        \max \lb m(x, y) \st y\in S(x) \rb & \text{if } t = \max
      \end{cases}
    \end{displaymath}
    for all $x\in \Sigma^*$; call this the \emph{optimal measure for $x$}.
    Let $m^*(x)$ be undefined if $S(x)=\emptyset$.
  \item Let $S^*(x)=\lb y\in\Sigma^* \st m(x, y) = m^*(x) \rb$; call this the \emph{set of optimal solutions for $x$}.
  \item Let $R(x, y)=\max\left( \frac{m(x, y)}{m^*(x)}, \frac{m^*(x)}{m(x, y)} \right)$; call this the \emph{performance ratio of the solution $y$}.
  \item Let $P_\exists = \lb x\in \Sigma^* \st S(x) \neq \emptyset \rb$; call this the \emph{existence problem}.
  \item Let
    \begin{displaymath}
      P_{opt<}=\lb (x, z) \in P_\exists\times\mathbb{N} \st \exists y\in\Sigma^*\colon m(x, y) < z \rb
    \end{displaymath}
    and
    \begin{displaymath}
      P_{opt>}=\lb (x, z) \in P_\exists\times\mathbb{N} \st \exists y\in\Sigma^*\colon m(x, y) > z \rb;
    \end{displaymath}
    call these the \emph{budget problems}.
  \item Let $f\colon \Sigma^*\to\Sigma^*$.
    We say \emph{$f$ produces solutions for $P$} if for all $x\in P_\exists$ we have $f(x)\in S(x)$.
    We say \emph{$f$ produces optimal solutions for $P$} if for all $x\in P_\exists$ we have $f(x)\in S^*(x)$.
  \end{enumerate}
\end{definition}

\begin{definition}
  Let $P$ be an optimization problem, let $r\colon \mathbb{N}\to\mathbb{N}$, and let $f\colon I\to \Sigma^*$.
  We say $f$ is an \emph{$r$-approximator for $P$} if it produces solutions for $P$ and $R(x, f(x)) \leq r(|x|)$ for all $x\in P_\exists$.

  If $r$ is the constant function with value $\delta$, we simply say $f$ is a \emph{$\delta$-approximator for $P$}.
\end{definition}

\begin{definition}
  Let $P$ be an optimization problem and let $f\colon I\times\mathbb{N}\to\Sigma^*$.
  We say $f$ is an \emph{approximation scheme for $P$} if for all $x\in P_\exists$ and all positive integers $k$ we have $f(x, k)\in S(x)$ and $R(x, f(x, k)) \leq 1 + 1 / k$.
\end{definition}

\subsection{Classes of optimization problems}

The study of \emph{efficient} approximations for \emph{intractable} problems begins with the following definition of \NP{} optimization problems.
We will adapt this definition to explore \emph{efficient and highly parallel} approximations for \emph{inherently sequential} problems.

\begin{definition}\label{def:npo}
  The complexity class \NPO{} is the class of all optimization problems $(I, S, m, t)$ such that the following conditions hold.
  \begin{enumerate}
  \item The instance set $I$ is decidable by a deterministic polynomial time Turing machine.
  \item The solution relation $S$ is decidable by a deterministic polynomial time Turing machine and is polynomially bounded (that is, the length of $y$ is bounded by a polynomial in the length of $x$ for all $(x, y)\in S$).
  \item The measure function $m$ is computable by a deterministic polynomial time Turing machine.
  \end{enumerate}
\end{definition}

The second condition is the most important in this definition; it is the analog of polynomial time verifiability in \NP.

\begin{definition}
  The complexity class \PO{} is the subclass of \NPO{} in which for each optimization problem $P$ there exists a function $f$ in \FP{} that produces optimal solutions for $P$.
\end{definition}

We now wish to translate these definitions to the setting of efficient and highly parallel verifiability.
In order to take advantage of results and techniques from the study of \NPO{} and \PO, we will start by considering the nondeterministic analog of \PO.
First we define the necessary circuit classes, then we define the corresponding classes of approximation problems.

\begin{definition}
  \mbox{}
  \begin{enumerate}
  \item \NC{} is the class of decision problems decidable by a uniform family of Boolean circuits with polynomial size, polylogarithmic depth, and fan-in two.
  \item \FNC{} is the class of functions computable by an \NC{} circuit in which the output of the circuit is (the binary encoding of) $f(x)$.
  \item $\NNC(f(n))$ is the class of languages computable by an \NC{} circuit family augmented with $O(f(n))$ nondeterministic gates for each input length $n$ \cite{wolf94}.
    A nondeterministic gate takes no inputs and yields a single (nondeterministic) output bit.

    If $\mathcal{F}$ is a class of functions, then $\NNC(\mathcal{F})=\bigcup_{f\in\mathcal{F}}{\NNC(f(n))}$.
  \end{enumerate}
\end{definition}

\NNCpoly, also known as \GC(\poly, \NC) \cite{cc97} and $\beta\P$ \cite{kf80}, is an unusual class which may warrant some further explanation.
\NC{} has the same relationship to \NNCpoly{} as \P{} does to \NP{} (thus an equivalent definition of \NNCpoly{} is one in which each language has an efficient and highly parallel verification procedure; as in the definition of \NPO{} in \autoref{def:npo}, it is this formulation which we use when defining \NNCO{} in \autoref{def:nnco}).
Wolf \cite{wolf94} notes that $\NNC(\log n)=\NC$ and $\NNC(\poly)=\NP$, and suggests that \NNC(\polylog) may be an interesting intermediary class, possibly incomparable with \P.
Cai and Chen \cite{cc97} prove that for each natural number $k$ and $i$, there is a complete problem for $\NNC^k(\log^i n)$ under logarithmic space reductions.

\begin{definition}\label{def:nnco}
  The complexity class \NNCOpoly{} is the class of all optimization problems $(I, S, m, t)$ such that the following conditions hold.
  \begin{enumerate}
  \item The instance set $I$ is decidable by an \NC{} circuit family.
  \item The solution relation $S$ is decidable by an \NC{} circuit family and is polynomially bounded (that is, the length of $y$ is bounded by a polynomial in the length of $x$ for all $(x, y)\in S$).
  \item The measure function $m$ is computable by an \FNC{} circuit family.
  \end{enumerate}
  For the sake of brevity, we write \NNCO{} instead of \NNCOpoly{}.
\end{definition}

Since $\NC\subseteq\P$, the inclusion $\NNCO\subseteq\NPO$ follows immediately from the definitions.
However, these definitions do not imply that the converse is true, since membership in \P{} does not imply membership in \NC.
In fact, there is evidence that $\NNCO \neq \NPO$.
\begin{proposition}[Thanks to Sam for this one.]
  $\NNCO = \NPO$ if and only if $\P = \NC$.
\end{proposition}
\begin{proof}
  We know $\NNCO \subseteq \NPO$ unconditionally from the preceding paragraph.
  If we suppose $\P = \NC$, then it follows immediately from the definitions that any optimization problem in $\NPO$ is also in $\NNCO$.

  Now suppose $\NNCO = \NPO$.
  If $C$ is a Boolean circuit with a single output, let $C(x)$ denote the output of $C$ (as a bit).
  Consider the optimization problem $Q$ defined by $Q = (I, S, m, t)$, where
  \begin{align*}
    I & = \{ C \, | \, C \text{ is a Boolean circuit} \}, \\
    S & = \{ (C, x) \, | \, C(x) = 1 \}, \\
    m(C, x) & = C(x), \text{ and} \\
    t & = \max.
  \end{align*}
  (Observe that $Q$ is an optimization form of the \textsc{Circuit Satisfiability} problem, where we have $m(C, x) \in \{0, 1\}$ for all circuits $C$ and all strings $x$.)
  $I \in \P$ because a correctly formatted Boolean circuit is a directed acyclic graph, and a depth first search (computable in deterministic polynomial time) can reveal if a given directed graph has a cycle.
  $S \in \P$ because it is exactly the \textsc{Circuit Value} problem, which is known to be in \P{} (in fact, it is \P-complete \cite[Problem~A.1.1]{ghr95}).
  $m \in \P$ because it is simply the function form of the \textsc{Circuit Value} problem.
  Therefore, $Q \in \NPO$.

  Since $\NNCO = \NPO$ by hypothesis, $Q \in \NNCO$.
  Hence, $S \in \NC$.
  The existence of an \NC{} algorithm for a \P-complete problem implies $\P = \NC$.
  Therefore, $\NNCO = \NPO$ if and only if $\P = \NC$.
\end{proof}

We can now proceed to define classes of approximable optimization problems contained in \NNCO.

\begin{definition}\label{def:ncx}
  Let $P\in\NNCO$.
  \begin{enumerate}
  \item $P\in\expApxNCO$ if there exists an $r$-approximator in \FNC{} for $P$, where $r(n)=2^{n^{O(1)}}$ for all $n\in\mathbb{N}$.
  \item $P\in\polyApxNCO$ if there exists an $r$-approximator in \FNC{} for $P$, where $r(n)=n^{O(1)}$ for all $n\in\mathbb{N}$.
  \item $P\in\logApxNCO$ if there exists an $r$-approxiator in \FNC{} for $P$, where $r(n)=O(\log n)$ for all $n\in\mathbb{N}$.
  \item $P\in\ApxNCO$ if there exists an $r$-approximator in \FNC{} for $P$, where $r(n)=O(1)$ for all $n\in\mathbb{N}$.
    (This class is also known as \NCX.)
  \item $P\in\NCAS$ if there exists an approximation scheme $f$ for $P$ such that $f_k\in\FNC$ for each $k\in\mathbb{N}$, where $f_k(x)=f(x, k)$ for all $x\in\Sigma^*$.
  \item $P\in\FNCAS$ if there exists an approximation scheme $f$ for $P$ such that $f\in\FNC$ in the sense that the size of the circuit is polynomial in both $|x|$ and $k$ and the depth of the circuit is polylogarithmic in both $|x|$ and $k$.
  \item $P\in\NCO$ if there exists a function $f$ in \FNC{} that produces optimal solutions for $P$.
  \end{enumerate}
\end{definition}

Each of these classes includes the one defined below it.

Each class also has a ``polynomially bounded'' variant, denoted by the subscript \pb, in which an optimization problem with measure $m$ and solution set $S$ has the property that there exists a polynomial $p$ such that $m(x, y) \leq p(|x|)$ for all $(x, y)\in S$.
Another common variant of these classes is the probabilistic versions of each (for example, randomized \NCAS{}, denoted \RNCAS), but we do not explore such classes in this work.

\begin{todo}
  What are the \PO-complete problems?
  Are these the problems for which it is \P-complete to produce an $\epsilon$ approximation for all $\epsilon$ (see \autoref{sec:approximationispcomplete})?
\end{todo}

\begin{todo}
  How does \PO{} compare to the \NC{} approximation classes?
  \cite[Figure~2.2]{dsst97} suggests that \P{} is incomparable to each of \FNCAS, \NCAS, and \ApxNCO, but provides no other explanation.
\end{todo}

The chain of inclusions given in \autoref{def:ncx} provides a hierarchy of classes which classify approximability of problems in \NNCO{}, and hence in \NPO.
However, our intention is to determine the approximability of optimization problems corresponding to \P-complete decision problems, not those corresponding to \NP-complete decision problems.
Therefore we define the following subclasses of \PO{} in order to more accurately capture the notion of highly efficient approximability of inherently sequential problems.

\begin{definition}\label{def:poprime}
  The complexity class \POp{} is the class of all optimization problems $(I, S, m, t)$ such that the following conditions hold.
  \begin{enumerate}
  \item The instance set $I$ is decidable by an \NC{} circuit family.
  \item The solution relation $S$ is decidable by an \NC{} circuit family and is polynomially bounded (that is, the length of $y$ is bounded by a polynomial in the length of $x$ for all $(x, y)\in S$).
  \item The measure function $m$ is computable by an \FNC{} circuit family.
  \item There exists a function $f$ in \FP{} that produces optimal solutions for $P$.
  \end{enumerate}
\end{definition}

\begin{definition}\label{def:ncxprime}
  Let $P\in\POp$.
  \begin{enumerate}
  \item $P\in\expApxNCOp$ if there exists an $r$-approximator in \FNC{} for $P$, where $r(n)=2^{n^{O(1)}}$ for all $n\in\mathbb{N}$.
  \item $P\in\polyApxNCOp$ if there exists an $r$-approximator in \FNC{} for $P$, where $r(n)=n^{O(1)}$ for all $n\in\mathbb{N}$.
  \item $P\in\logApxNCOp$ if there exists an $r$-approxiator in \FNC{} for $P$, where $r(n)=O(\log n)$ for all $n\in\mathbb{N}$.
  \item $P\in\ApxNCOp$ if there exists an $r$-approximator in \FNC{} for $P$, where $r(n)=O(1)$ for all $n\in\mathbb{N}$.
    (This class is also known as \NCX.)
  \item $P\in\NCASp$ if there exists an approximation scheme $f$ for $P$ such that $f_k\in\FNC$ for each $k\in\mathbb{N}$, where $f_k(x)=f(x, k)$ for all $x\in\Sigma^*$.
  \item $P\in\FNCASp$ if there exists an approximation scheme $f$ for $P$ such that $f\in\FNC$ in the sense that the size of the circuit is polynomial in both $|x|$ and $k$ and the depth of the circuit is polylogarithmic in both $|x|$ and $k$.
  \end{enumerate}
\end{definition}

Observe that $\POp = \PO \cap \NNCO$ by definition, and similarly $\ApxNCOp = \PO \cap \ApxNCO$, etc.
\autoref{fig:inclusions} shows the inclusions among some of the complexity classes defined in this section.
\begin{figure}
  \caption{%
    Inclusions among some classes of approximable optimization problems.
    The complexity class at the tail of each arrow is a subset of the complexity class at the head of the arrow.
    \label{fig:inclusions}}
  \begin{center}
    \begin{tikzpicture}

      \draw (0, 7) node(NPO) {\NPO};

      \draw (-2, 5) node(NNCO) {\NNCO};
      \draw (-2, 4) node(ApxNCO) {\ApxNCO};
      \draw (-2, 3) node(NCAS) {\NCAS};

      \draw (1, 6) node(ApxPO) {\ApxPO};
      \draw (1, 5) node(PTAS) {\PTAS};
      \draw (1, 4) node(PO) {\PO};
      \draw (0, 3) node(POp) {\POp};
      \draw (0, 2) node(ApxNCOp) {\ApxNCOp};
      \draw (0, 1) node(NCASp) {\NCASp};

      \draw (0, 0) node(NCO) {\NCO};

      \path[->]
      (NCO) edge (NCASp)
      (NCASp) edge (ApxNCOp)
      (ApxNCOp) edge (POp)
      (POp) edge (PO)
      (PO) edge (PTAS)
      (PTAS) edge (ApxPO)
      (ApxPO) edge (NPO)

      (NCAS) edge (ApxNCO)
      (ApxNCO) edge (NNCO)

      (NCASp) edge (NCAS)
      (ApxNCOp) edge (ApxNCO)
      (POp) edge (NNCO)

      (NCAS) edge (PTAS)
      (ApxNCO) edge (ApxPO)
      (NNCO) edge (NPO);
    \end{tikzpicture}
  \end{center}
\end{figure}

\section{Reductions among approximation problems}

There are many reductions for approximation problems; nine of them are defined in a survey paper by Crescenzi \cite{crescenzi97}, and there are more defined elsewhere.
We will use a logarithmic space-bounded version of the ``AP reduction'', considered by approximation experts to be the a reasonable reduction to use when constructing complete problems \cite[Section~2]{crescenzi97} \cite[Section~8.6]{acgkmp99}.

\begin{definition}{\cite[Definition~9]{ckst95}}
  Let $P$ and $Q$ be optimization problems in \NNCO, with $P=(I_P, S_P, m_p, t_P)$ and $Q=(I_Q, S_Q, m_Q, t_Q)$.
  We say \emph{$P$ AP reduces to $Q$} and write $P\APr Q$ if there exist functions $f\colon\Sigma^*\to\Sigma^*$ and $g\colon\Sigma^*\to\Sigma^*$, and there exists a constant $\alpha\in\mathbb{R}$ such that:
  \begin{enumerate}
  \item For all $x\in I_P$ and all $r > 1$, we have $f(x, r)\in I_Q$.
  \item For all $x\in I_P$, all $r > 1$, and all $y\in S_Q(f(x, r))$, we have $g(x, y, r)\in S_P(x)$.
  \item $f$ and $g$ are computable in logarithmic space for any fixed $r$.
  \item For all $x\in I_P$, all $r > 1$, and all $y\in S_Q(f(x, r))$, we have $R_Q(f(x, r), y) \leq r \implies R_P(x, g(x, y, r)) \leq 1 + \alpha(r - 1)$.
  \end{enumerate}
\end{definition}

We bound the AP reduction to logarithmic space instead of allowing it be a \FNC{} circuit family because 1. the former notion of reduction is more restrictive and hence implies the latter, 2. existing results on approximability and approximation classes use the former, and 3. it eases analysis in some proofs.

\begin{proposition}
  Let $\mathcal{C}$ be one of the complexity classes \NCO, \NCAS, \ApxNCO, \logApxNCO, \polyApxNCO, \expApxNCO, or \NNCO.
  Suppose $P\in\NNCO$ and $Q\in\mathcal{C}$.
  If $P\APr Q$ then $P\in \mathcal{C}$.
  In other words, $\mathcal{C}$ is closed under $\APr$ reductions.
\end{proposition}
\begin{proof}
  \begin{todo}
    fill me in
  \end{todo}
\end{proof}

\section{Complexity of extant parallel approximations}

For a listing of somewhat contemporary results on efficient \emph{sequential} approximation, see \cite{compendium}.

\begin{proposition}
  \mbox{}
  \begin{itemize}
  \item \NNCO{} contains \nncoproblems.
  \item \expApxNCO{} contains \expapxncoproblems.
  \item \polyApxNCO{} contains \polyapxncoproblems.
  \item \logApxNCO{} contains \logapxncoproblems
  \item \ApxNCO{} contains \apxncoproblems.
  \item \NCAS{} contains \ncasproblems.
  \item \FNCAS{} contains \fncasproblems.
  \item \NCO{} contains \ncoproblems.
  \end{itemize}
\end{proposition}

Some problems exhibit ``threshold'' behavior: for certain values of a parameter (for example, $0 < \epsilon < \frac{1}{2}$) the approximation problem is computable in \NC, but for other values (for example, $\frac{1}{2} \leq \epsilon < 1$) the approximation problem is \P-complete (or \NP-complete).
This implies that those problems cannot have a polynomial time approximation scheme (that is, they are not in \PTAS), unless $\P = \NP$.

\section{Completeness for classes of problems admitting parallel approximations}
\label{sec:completeness}

\begin{definition}
  Let $\mathcal{C}$ be one of the complexity classes \NCO, \NCAS, \ApxNCO, \logApxNCO, \polyApxNCO, \expApxNCO, or \NNCO.
  An optimization problem $Q$ is \emph{$\mathcal{C}$-hard} if for all $P\in\mathcal{C}$, we have $P\APr Q$.
  If furthermore $Q\in\mathcal{C}$, we say it is $\mathcal{C}$-complete.
\end{definition}

\subsection{Completeness of optimization problems corresponding to \texorpdfstring{\NP}{NP}-complete problems}

We wish to demonstrate complete problems for each of these parallel approximation classes.
To do this we start with optimization problems that have the following properties:
\begin{enumerate}
\item The corresponding budget problem is \NP-complete.
\item The optimization problem is complete in one of the polynomial time approximation classes (\ApxPO, \PTAS, etc.).
\end{enumerate}
We then adapt the original proofs of completeness to show that the \emph{same problem} is complete in the corresponding \NC{} approximation class (\ApxNCO, \NCAS, etc.) under the (possibly) more restrictive logarithmic space AP reduction.

\begin{conjecture}
  \textsc{Maximum Weighted Satisfiability} is \NNCO-complete.
\end{conjecture}
\begin{justification}
  \textsc{Maximum Weighted Satisfiability} is \NPO-complete \cite{ckst95} and $\NNCO\subseteq\NPO$.
\end{justification}

\begin{conjecture}
  \textsc{Minimum Traveling Salesperson Problem} is complete for \expApxNCO{} under $\APr$ reductions.
\end{conjecture}
\begin{justification}
  \textsc{Minimum Traveling Salesperson Problem} is complete for \expApxPO{} under ``MPTAS reductions'' \cite[Corollary~1]{ep06}.
\end{justification}

It is \P-complete to compute a $\rho$-approximation for \textsc{Minimum-cost Maximum Flow} where $\rho$ is a polynomial in the length of the input \cite{sw92}.
It seems that this is true for all polynomials $\rho$, perhaps implying that this problem is not in \polyApxNCO{}, but it is not totally clear from the proof.

\begin{conjecture}
  \textsc{Maximum Clique} is \polyApxNCO-complete.
\end{conjecture}
\begin{justification}
  \textsc{Maximum Clique} is complete for \polyApxPO{} under ``PTAS reductions'' \cite[Example~2.48]{cks01} \cite{kmsv99} \cite{ep10}.
\end{justification}

\begin{conjecture}
  \textsc{Minimum Set Cover} is \logApxNCO-complete.
\end{conjecture}
\begin{justification}
  \textsc{Minimum Set Cover} is complete for \logApxPO{} under ``MPTAS reductions'' \cite[Example~2.48]{cks01} \cite[Theorem~5]{ep06} \cite[Theorem~27]{ep10}.

  Also, \textsc{Minimum Set Cover} is complete for $\logApxPO_{pb}$ under ``E reductions''.
\end{justification}

In \cite{sx95}, the authors prove that \textsc{Maximum Bounded Weighted Satisfiability} is complete for \ApxNCO{} (there called ``\NCX'') under a very unrestrictive type of reduction called an ``\NCAS{} reduction''.
Unfortunately, the proof there is very sketchy.
Their proof adapts the technique of \cite{cp91} for constructing a canonical complete problem for \ApxPO{} (there called ``\APX'').

\begin{theorem}
  \textsc{Maximum Bounded Weighted Satisfiability} is complete for \ApxNCO{} under \NCAS{} reductions.
\end{theorem}

\begin{conjecture}
  \mbox{}
  \begin{enumerate}
  \item \textsc{Planar Maximum Satisfiability} is \NCAS-complete.
  \item \textsc{Planar Maximum Independent Set} is \NCAS-complete.
  \end{enumerate}
\end{conjecture}
\begin{justification}
  \mbox{}
  \begin{enumerate}
  \item \textsc{Planar Maximum Satisfiability} is in \PMPSAT, which is a subset of \PTAS{} and \emph{may} be a syntactic characterization of \PTAS{} \cite{km96}.
  \item \textsc{Planar Maximum Independent Set} is complete for \PTAS{} under ``FT reductions'' \cite[Theorem~6]{bep06}.
  \end{enumerate}
\end{justification}

\begin{conjecture}
  \textsc{0-1 Knapsack} is \FNCAS-complete.
\end{conjecture}
\begin{justification}
  \textsc{0-1 Knapsack} is in $\FPTAS\setminus\PO$ \cite[Section~3.2]{ep10} and is in \FNCAS{} \cite[Theorem~2]{mayr88}.
\end{justification}

\subsection{Syntactic characterization of \texorpdfstring{\ApxNCO}{ApxNCO}}

In \cite{py91}, the authors introduce a wealth of problems which are complete under ``L reductions'' for \MaxSNP, the class of maximization problems in strict \NP{} (\SNP), which is a syntactic characterization of \NP.
Further work showed that the closure of \MaxSNP{} under ``\PTAS{} reductions'' equals $\ApxPO_{pb}$ \cite{kmsv99}.

\begin{todo}
  We know that $\FO[\log^{O(1)} n] = \NC$ \cite[Theorem~5.2]{immerman99}; can we use this to construct a syntactic definition of $\ApxNCO$?
  Can we more easily construct a complete problem using this characterization?
\end{todo}

\subsection{Completeness of optimization problems corresponding to \texorpdfstring{\P}{P}-complete problems}
\label{sec:pcompleteapprox}

All of the completeness results seen in the previous section are based on the optimization form of \NP-complete problems.
While it is obviously important to provide efficient and highly parallel approximation algorithms for problems which are both intractable and inherently sequential, it is also desirable to provide highly parallel approximation algorithms for problems which are tractable but still inherently sequential.

\begin{todo}
  Produce a \P-complete problem which is complete for \ApxNCO{} (and then for each of the other approximation classes) by considering a restriction of an \NP-complete problem and following the same proof.
\end{todo}

\begin{todo}
  Produce a \P-complete problem which is complete for \ApxNCO{} (and then for each of the other approximation classes) by considering a relaxation of an \NL-complete problem and following a similar proof (this will be harder because a logarithmic space-bounded Turing machine can be described by a small directed graph representing its configurations and transitions).
\end{todo}

\begin{todo}
  Suppose $Q$ is an optimization problem, so $Q=(I, S, m, t)$, and $\hat{Q}$ is the budget problem for $Q$ which corresponds to $t$.
  Is it true that if $Q$ is \PO-complete then $\hat{Q}$ is \P-complete?
  Is the converse true?
\end{todo}

\subsection{Consequences of complete approximations for both \texorpdfstring{\NP}{NP}-complete and \texorpdfstring{\P}{P}-complete problems}

It may, at first glance, be a bit unsettling to see that there exist, for example, \ApxNCO-complete optimization problems which are based on both \NP-complete problems and \P-complete problems, since this implies a logarithmic space approximation-preserving reduction between the optimization problems.
Should such a reduction, from an optimization problem based on an \NP-complete problem to an optimization problem based on a \P-complete problem, distress us?

\begin{todo}
  What are the consequences of such a reduction?
  Does this imply \P=\NP?
  It shouldn't, because approximations of optimization problems shouldn't define solutions to decision problems.
\end{todo}
\begin{todo}[Thanks to Rita for this one]
  Do there exist, for example, \ApxPO-complete optimization problems which are based on both \NP-complete problems and \PSPACE-complete problems?
  \STP-complete problems?
\end{todo}

Suppose that $P$ is the \ApxNCO-complete optimization problem with an \NP-complete budget problem, $P_{opt>}$.
Suppose that $Q$ is the \ApxNCO-complete optimization problem with a \P-complete budget problem, $Q_{opt>}$.
In order to show that this situation implies, say, $\P=\NP$, a likely course of attack would be to produce a sequence of reductions (of an appropriate type) showing that $P_{opt>} \leq P \leq Q \leq Q_{opt>}$.
The middle reduction exists since $Q$ is \ApxNCO-complete and $P\in\ApxNCO$ (note that $P$ needs only to be in \ApxNCO; it does not need to be complete for the class), so we would need to prove the first and last reductions.

To prove the first reduction would require using an algorithm which produces approximate solutions for $P$ to decide if there exists \emph{any} solution whose measure meets some bound.
Since we don't know which approximate solution will be produced by the algorithm, it seems difficult to explore all possible solutions to find one which meets the bound.

To prove the last reduction would require using an algorithm which decides if there exists any solution whose measure meets some bound to produce an approximate solution.

\begin{todo}
  Explain why this last reduction is unlikely to exist.
\end{todo}

\section{Translating hardness of approximation results to \texorpdfstring{\NC}{NC}}

The celebrated \PCP{} theorem gives a precise characterization of \NP{} in terms of probabilistic verifiers with bounded randomness and queries, specifically that $\NP = \PCP(\lg n, 1)$ \cite{pcp}.
This characterization allowed many hardness of approximation results for optimization problems in \NPO{} corresponding to \NP-complete decision problems.

\begin{todo}
  Can the same be done for \NNC?
  Is there a \PCP{} characterization for \NNC?
\end{todo}

\section{Parallel approximations for other \texorpdfstring{\P}{P}-complete problems}

In this section, we will use our results from \autoref{sec:pcompleteapprox} to determine upper bounds on the approximation of other \P-complete problems.

\begin{todo}
  Create a list of \P-complete optimization problems, and determine reductions to the complete problems from the previous section.
\end{todo}

\section{Problems for which parallel approximation is \texorpdfstring{\P}{P}-complete}
\label{sec:approximationispcomplete}

In \cite[Section~10.2]{ghr95}, the authors provide a very informal statement that ``there are no \NC{} approximation algorithms'' for the following problems: \textsc{Lexicographically First Maximal Independent Set Size}, \textsc{Unit Resolution}, \textsc{Generability}, \textsc{Path Systems}, and \textsc{Circuit Value Problem}.
They further state that the following problems exhibit threshold behavior, in the sense that computing an $\epsilon$-approximation is \P-complete if $\epsilon\geq 2$ but is in \NCAS{} if $\epsilon<2$: \textsc{High Degree Subgraph} and \textsc{High Connectivity Subgraph}.
Most of these results come from \cite{ss89}.

\begin{todo}
  State the formal results in the terminology of this work.
\end{todo}

An optimization problem for which any constant-factor approximation is \P-complete implies that the optimization problem is not in \ApxNCO{} (unless $\P=\NC$).
However, it may still be the case that these \P-complete optimization problems are in \logApxNCO, \polyApxNCO, \expApxNCO, or \NNCO.

\begin{todo}
  Is that correct?
\end{todo}

\subsection{Classifying existing results}

\begin{conjecture}
  \textsc{Maximum Bounded Weighted Circuit Evaluation} is complete for \ApxNCOp{} under \NCAS{} reductions.
\end{conjecture}

\begin{theorem}[{\cite[Theorem~1]{ss89}}]
  For all $\epsilon \in (0, 1)$, \textsc{$\epsilon$-DPATH} is \P-complete.
\end{theorem}

\begin{conjecture}
  \textsc{Maximum DPATH} is complete for \logApxNCOp{} under $\APr$ reductions.
\end{conjecture}

\begin{theorem}[{\cite[Theorem~2]{ss89}}]
  For all $\epsilon \in (0, 1)$, \textsc{$\epsilon$-DUNIT} is \P-complete.
\end{theorem}

\begin{conjecture}
  \textsc{Maximum DUNIT} is complete for \logApxNCOp{} under $\APr$ reductions.
\end{conjecture}

\begin{theorem}[{\cite{kl88}}]
  For all $\epsilon \in (0, 1)$, \textsc{$\epsilon$-Circuit Depth of Ones} is \P-complete.
\end{theorem}

\begin{conjecture}
  \textsc{Maximum Circuit Depth of Ones} is complete for the class \logApxNCOp{} under $\APr$ reductions.
\end{conjecture}

\begin{theorem}[{\cite[Theorem~4]{ss89}}]
  For all $\epsilon \in (0, 1)$, \textsc{$\epsilon$-DGEN} is \P-complete.
\end{theorem}

\begin{conjecture}
  \textsc{Maximum DGEN} is complete for \logApxNCOp{} under $\APr$ reductions.
\end{conjecture}

\begin{theorem}[{\cite{serna91}}]
  For all $\epsilon \in (0, 1)$, \textsc{$\epsilon$-Linear Programming} is \P-complete (for both solution approximation and value approximation).
\end{theorem}

\begin{conjecture}
  \textsc{Maximum Linear Programming} is complete for the class \logApxNCOp{} under $\APr$ reductions.
\end{conjecture}

\begin{theorem}[{\cite[Theorem~4]{kks91}}]
  For all $\epsilon \in (0, 1)$, \textsc{$\epsilon$-Reliable Connectivity Problem for in-edges} is \P-complete.
\end{theorem}

\begin{conjecture}
  \textsc{Maximum Reliable Connectivity Problem for in-edges} is complete for \logApxNCOp{} under $\APr$ reductions.
\end{conjecture}

\begin{theorem}[{\cite[{Theorem~4 and Theorem~5}]{am84}}]
  \mbox{}
  \begin{enumerate}
  \item For all $\epsilon \in (0, \frac{1}{2})$, \textsc{$\epsilon$-High Degree Subgraph} is \P-complete.
  \item For all $\epsilon \in (\frac{1}{2}, 1)$, \textsc{$\epsilon$-High Degree Subgraph} is in $\NC$.
  \end{enumerate}
\end{theorem}

\begin{conjecture}
  \textsc{Maximum High Degree Subgraph} is complete for the class \ApxNCOp{} under $\APr$ reductions.
\end{conjecture}

\begin{theorem}[{\cite[{Theorem~6}]{ss89}}]
  \mbox{}
  \begin{enumerate}
  \item For all $\epsilon \in (0, \frac{1}{2})$, \textsc{$\epsilon$-High Connectivity Subgraph} is \P-complete.
  \item For all $\epsilon \in (\frac{1}{2}, 1)$, \textsc{$\epsilon$-High Connectivity Subgraph} is in $\NC$.
  \end{enumerate}
\end{theorem}

\begin{conjecture}
  \textsc{Maximum High Connectivity Subgraph} is complete for \ApxNCO{} under $\APr$ reductions.
\end{conjecture}

\section{About this work}

Copyright 2012 Jef{}frey Finkelstein.

This work is licensed under the Creative Commons Attribution-ShareAlike License 3.0.
Visit \mbox{\url{https://creativecommons.org/licenses/by-sa/3.0/}} to view a copy of this license.

The \LaTeX{} markup which generated this document is available on the World Wide Web at \mbox{\url{https://github.com/jfinkels/ncapproximation}}.
It is also licensed under the Creative Commons Attribution-ShareAlike License.

The author can be contacted via email at \email{jeffreyf@bu.edu}.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
