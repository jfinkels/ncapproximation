\documentclass[draft]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{complexity}
\usepackage[pdftitle={Definitions and reductions for NC approximation problems}, pdfauthor={Jeffrey Finkelstein}]{hyperref}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{theorem}{Theorem}

\mathchardef\mhyphen="2D

\newcommand{\Er}{\leq_E^{L}}
\newcommand{\email}[1]{\href{mailto:#1}{\nolinkurl{#1}}}
\newcommand{\lb}{\left\{}
\newcommand{\rb}{\right\}}
\newcommand{\st}{\,\middle|\,}

\newcommand{\apxncoproblems}{%
  Induced Subgraph of High Weight for Linear Extremal Properties \cite{dsst97}
  Maximum Acyclic Subgraph \cite[Section~7.4]{dsst97}
  Minimum $k$-Center \cite[Section~7.4]{dsst97}
  $k$-Switching Network \cite[Section~7.4]{dsst97}
  Maximum Bounded Weighted Satisfiability \cite[Theorem~4]{sx95}
}
\newcommand{\expapxncoproblems}{}
\newcommand{\frncasproblems}{%
  Maximum Flow \cite[Theorem~4.5.2]{dsst97},
  Maximum Weight Perfect Matching \cite[Theorem~4.5.2]{dsst97},
  Maximum Weight Matching \cite[Theorem~4.5.2]{dsst97}
}
\newcommand{\fncasproblems}{%
  Subset Sum \cite[Theorem~4.1.4]{dsst97},
  Maximum Satisfiability \cite[Theorem~8]{trevisan98},
  Minimum Weight Vertex Cover \cite[Theorem~5.3.6]{dsst97},
  0-1 Knapsack \cite[Theorem~2]{mayr88}
  Bin Packing \cite[Theorem~3]{mayr88}
}
\newcommand{\ncasproblems}{%
  Positive Linear Programming \cite[Theorem~5.1.11]{dsst97},
  Maximum $k$-Constraint Satisfaction Problem \cite[Corollary~13]{trevisan98},
  Maximum Matching \cite[Theorem~5.2.1]{dsst97},
  Maximum Flow \cite[Theorem~5.2.2]{dsst97},
  Maximum Weight Matching \cite[Theorem~5.2.2]{dsst97},
  Maximum Independent Set \cite[Theorem 6.4.1]{dsst97}
}
\newcommand{\rncasproblems}{%
  Minimum Metric Traveling Salesperson \cite[Theorem~7.1.1]{dsst97}
}
\newcommand{\ncoproblems}{}
\newcommand{\polyapxncoproblems}{}

\author{Jef{}frey Finkelstein}
\date{\today}
\title{Definitions and reductions for \texorpdfstring{\NC}{NC} approximation problems}

\begin{document}

\maketitle

\NC{} is the class of computational problems decidable by a Boolean circuit of polynomial size and polylogarithmic depth.
Such problems are considered both ``efficient'' (since $\NC\subseteq\P$) and ``highly parallel'' (since we might consider each gate in the circuit to be a processor working in parallel and the low depth of the circuit a small number of steps).
By contrast, problems which are \P-complete (under \NC{} reductions) are considered ``inherently sequential''.
Furthermore, all \NP-hard and \PSPACE-hard problems are also inherently sequential, since $\P\subseteq\NP\subseteq\PSPACE$.
Just as we hope to find efficient approximation algorithms for optimization problems for which it is intractable to compute an exact solution, so too do we hope to find efficient and highly parallel approximation algorithms for optimization problems for which computing the exact solution is inherently sequential.

\section{Definitions of \texorpdfstring{\NC}{NC} approximation classes}

We adapt the definitions of \cite{tantau07} from logspace approximability to \NC{} approximability.
Throughout this work, $\Sigma=\{0, 1\}$ and inputs and outputs are encoded in binary.

\begin{definition}[\cite{acgkmp99}]
  An \emph{optimization problem} is a four-tuple, $(I, S, m, t)$, where $I\subseteq \Sigma^*$ and is called the \emph{instance set}, $S\subseteq I\times \Sigma^*$ and is called the \emph{solution relation}, $m\colon S\to \mathbb{N}^+$ and is called the \emph{measure function}, and $t\in\{\min, \max\}$ and is called the type (of the optimization).
\end{definition}

\begin{definition}[\cite{tantau07}]
  Let $P$ be an optimization problem, so $P=(I, S, m, t)$, and let $x\in I$.
  \begin{enumerate}
  \item Let $S(x)=\lb y\in\Sigma^* \st (x, y)\in S \rb$; call this the \emph{solutions for $x$}.
  \item Define $m^*(x)$ by
    \begin{displaymath}
      m^*(x) =
      \begin{cases}
        \min \lb m(x, y) \st y\in S(x) \rb & \text{if } t = \min \\
        \max \lb m(x, y) \st y\in S(x) \rb & \text{if } t = \max
      \end{cases}
    \end{displaymath}
    for all $x\in \Sigma^*$; call this the \emph{optimal measure for $x$}.
    Let $m^*(x)$ be undefined if $S(x)=\emptyset$.
  \item Let $S^*(x)=\lb y\in\Sigma^* \st m(x, y) = m^*(x) \rb$; call this the \emph{set of optimal solutions for $x$}.
  \item Let $R(x, y)=\max\left( \frac{m(x, y)}{m^*(x)}, \frac{m^*(x)}{m(x, y)} \right)$; call this the \emph{performance ratio of the solution $y$}.
  \item Let $P_\exists = \lb x\in \Sigma^* \st S(x) \neq \emptyset \rb$; call this the \emph{existence problem}.
  \item Let
    \begin{displaymath}
      P_{opt<}=\lb (x, z) \in P_\exists\times\mathbb{N} \st \exists y\in\Sigma^*\colon m(x, y) < z \rb
    \end{displaymath}
    and
    \begin{displaymath}
      P_{opt>}=\lb (x, z) \in P_\exists\times\mathbb{N} \st \exists y\in\Sigma^*\colon m(x, y) > z \rb;
    \end{displaymath}
    call these the \emph{budget problems}.
  \item Let $f\colon \Sigma^*\to\Sigma^*$.
    We say \emph{$f$ produces solutions for $P$} if for all $x\in P_\exists$ we have $f(x)\in S(x)$.
    We say \emph{$f$ produces optimal solutions for $P$} if for all $x\in P_\exists$ we have $f(x)\in S^*(x)$.
  \end{enumerate}
\end{definition}

\begin{definition}
  \mbox{}
  \begin{enumerate}
  \item \NC{} is the class of decision problems decidable by a uniform family of Boolean circuits with polynomial size, polylogarithmic depth, and fan-in two.
  \item \FNC{} is the class of functions computable by an \NC{} circuit in which the output of the circuit is (the binary encoding of) $f(x)$.
  \item $\NNC(f(n))$ \cite{wolf94} is the class of languages computable by an \NC{} circuit family augmented with $O(f(n))$ nondeterministic gates for each input length $n$.
    A nondeterministic gate takes no inputs and a single (nondeterministic) output bit.
  \end{enumerate}
\end{definition}

\begin{definition}
  The complexity class \NNCO{} is the class of all optimization problems $(I, S, m, t)$ such that the following conditions hold.
  \begin{enumerate}
  \item The instance set $I$ is decidable by an \NC{} circuit family.
  \item The solution relation $S$ is decidable by an \NC{} circuit family and is polynomially bounded (that is, the length of $y$ is bounded by a polynomial in the length of $x$ for all $(x, y)\in S$).
  \item The measure function $m$ is computable by an \FNC{} circuit family.
  \end{enumerate}

  The class \NCO{} is the subset of \NNCO{} in which for each optimization problem there exists a function in \FNC{} that produces optimal solutions for it.
\end{definition}

\begin{definition}
  Let $P$ be an optimization problem, let $r\colon \mathbb{N}\to\mathbb{N}$, and let $f\colon I\to \Sigma^*$.
  We say $f$ is an \emph{$r$-approximator for $P$} if it produces solutions for $P$ and $R(x, f(x)) \leq r(|x|)$ for all $x\in P_\exists$.

  If $r$ is the constant function with value $\delta$, we simply say $f$ is a \emph{$\delta$-approximator for $P$}.
\end{definition}

\begin{definition}
  Let $P$ be an optimization problem and let $f\colon I\times\mathbb{N}\to\Sigma^*$.
  We say $f$ is an \emph{approximation scheme for $P$} if for all $x\in P_\exists$ and all positive integers $k$ we have $f(x, k)\in S(x)$ and $R(x, f(x, k)) \leq 1 + 1 / k$.
\end{definition}

\begin{definition}
  Let $P\in\NNCO$.
  \begin{enumerate}
  \item $P\in\expApxNCO$ if there exists an $r$-approximator in \FNC{} for $P$, where $r(n)=2^{n^{O(1)}}$ for all $n\in\mathbb{N}$.
  \item $P\in\polyApxNCO$ if there exists an $r$-approximator in \FNC{} for $P$, where $r$ is a polynomial.
  %% \item $P\in\logApxNCO$ if there exists an $r$-approxiator in \FNC{} for $P$, where $r(n)=O(\lg n)$.
  \item $P\in\ApxNCO$ if there exists an $r$-approximator in \FNC{} for $P$, where $r$ is a constant function.
    (This class is also known as \NCX.)
  \item $P\in\NCAS$ if there exists an approximation scheme $f$ for $P$ such that $f_k\in\FNC$ for each $k\in\mathbb{N}$, where $f_k(x)=f(x, k)$ for all $x\in\Sigma^*$.
  \item $P\in\FNCAS$ if there exists an approximation scheme $f$ for $P$ such that $f\in\FNC$ in the sense that the size of the circuit is polynomial in both $|x|$ and $k$ and the depth of the circuit is polylogarithmic in both $|x|$ and $k$.
  \end{enumerate}
\end{definition}

\begin{proposition}
  $\NCO \subseteq \FNCAS \subseteq \NCAS \subseteq \ApxNCO \subseteq \polyApxNCO \subseteq \expApxNCO \subseteq \NNCO$
\end{proposition}

\section{Reductions among approximation problems}

There are many reductions for approximation problems.
Although the authors of \cite{ckst95} consider it to be too restrictive for polynomial time approximation classes, we will use the \emph{error-preserving reduction} (E-reduction).
We bound the E-reduction to logarithmic space instead of requiring that it be a \FNC{} circuit family because 1. the former is (probably) a stronger notion of reduction and hence implies the latter, 2. existing results on approximability and approximation classes use the former, and 3. it eases analysis in some proofs.

\begin{definition}
  let $P$ and $Q$ be optimization problems.
  We write $P\Er Q$ if there exists a triple $(f, g, \alpha)$, where $f$ and $g$ are functions computable in logarithmic space and $\alpha\in\mathbb{N}$, such that for all $x\in P_\exists$ we have $f(x)\in Q_\exists$ and for all $y\in S_Q(f(x))$ we have $g(x, y)\in S_P(x)$ and $R_P(x, g(x, y)) - 1 \leq \alpha \cdot (R_Q(f(x), y) - 1)$.
\end{definition}

\begin{proposition}
  Let $\mathcal{C}\in \{\NCO, \NCAS, \ApxNCO, \polyApxNCO, \expApxNCO, \NNCO\}$.
  Suppose $P\in\NNCO$ and $Q\in\mathcal{C}$.
  If $P\Er Q$ then $P\in \mathcal{C}$.
  In other words, $\mathcal{C}$ is closed under $\Er$ reductions.
\end{proposition}
\begin{proof}
  TODO: fill me in by following the proof from \cite{tantau07}.
\end{proof}

\section{Complexity of extant parallel approximations}

For a listing of somewhat contemporary results on efficient \emph{sequential} approximation, see \cite{compendium}.

\begin{proposition}
  \mbox{}
  \begin{itemize}
  \item \expApxNCO{} contains \expapxncoproblems.
  \item \polyApxNCO{} contains \polyapxncoproblems.
  \item \ApxNCO{} contains \apxncoproblems.
  \item \NCAS{} contains \ncasproblems.
  \item \FNCAS{} contains \fncasproblems.
  \item \NCO{} contains \ncoproblems.
  \end{itemize}
\end{proposition}

Some problems exhibit ``threshold'' behavior: for certain values of a parameter (for example, $0 < \epsilon < 1/2$) the approximation problem is computable in \NC, but for other values (for example, $1/2 \leq \epsilon < 1$) the approximation problem is \P-complete.

\section{Complete problems}

\begin{definition}
  For $\mathcal{C}\in \{\NCO, \NCAS, \ApxNCO, \polyApxNCO, \expApxNCO, \NNCO\}$, an optimization problem $Q$ is \emph{$\mathcal{C}$-hard} if for all $P\in\mathcal{C}$, we have $P\Er Q$.
  If further $Q\in\mathcal{C}$, we say it is $\mathcal{C}$-complete.
\end{definition}

We wish to demonstrate complete problems for each of these approximation classes.
%To do this we start with \NP-complete optimization problems.

In \cite{sx95}, the authors prove that Maximum Bounded Weighted Satisfiability is complete for \ApxNCO{} (there called ``\NCX'') under a less restrictive type of reduction called an ``\NCAS{} reduction''.
We show that their proof works also for E-reductions.
\begin{theorem}
  Maximum Bounded Weighted Satisfiability is \ApxNCO-complete.
\end{theorem}
\begin{proof}
  TODO: fill me in by following the proof from \cite{sx95}; unfortunately, their proof is very sketchy.
\end{proof}

\section{About this work}

Copyright 2012 Jef{}frey Finkelstein.

This work is licensed under the Creative Commons Attribution-ShareAlike License 3.0.
Visit \mbox{\url{https://creativecommons.org/licenses/by-sa/3.0/}} to view a copy of this license.

The \LaTeX{} markup which generated this document is available on the World Wide Web at \mbox{\url{https://github.com/jfinkels/parallel}}.
It is also licensed under the Creative Commons Attribution-ShareAlike License.

The author can be contacted via email at \email{jeffreyf@bu.edu}.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
